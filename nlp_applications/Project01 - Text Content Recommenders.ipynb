{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://colab.research.google.com/github/dipanjanS/nlp_workshop_odsc19/blob/master/Module05%20-%20NLP%20Applications/Project01%20-%20Text%20Content%20Recommenders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGdpBKaHXuoc"
   },
   "source": [
    "# Movie Recommendations with Document Similarity\n",
    "\n",
    "Recommender systems are one of the popular and most adopted applications of machine learning. They are typically used to recommend entities to users and these entites can be anything like products, movies, services and so on. \n",
    "\n",
    "Popular examples of recommendations include,\n",
    "- Amazon suggesting products on its website\n",
    "- Amazon Prime, Netflix, Hotstar recommending movies\\shows\n",
    "- YouTube recommending videos to watch\n",
    "\n",
    "Typically recommender systems can be implemented in three ways:\n",
    "\n",
    "- Simple Rule-based Recommenders: Typically based on specific global metrics and thresholds like movie popularity, global ratings etc.\n",
    "- Content-based Recommenders: This is based on providing similar entities based on a specific entity of interest. Content metadata can be used here like movie descriptions, genre, cast, director and so on\n",
    "- Collaborative filtering Recommenders: Here we don't need metadata but we try to predict recommendations and ratings based on past ratings of different users and specific items.\n",
    "\n",
    "We will be building a movie recommendation system here where based on data\\metadata pertaining to different movies, we try and recommend similar movies of interest!\n",
    "\n",
    "![](https://i.imgur.com/c7Go7d3.png)\n",
    "\n",
    "Since our focus in not really recommendation engines but NLP, we will be leveraging the text-based metadata for each movie to try and recommend similar movies based on specific movies of interest. This falls under content-based recommenders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "-U-mW8t5YDFH",
    "outputId": "167cb216-feb9-47cd-a27f-06c0fada3534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (0.0.17)\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.1.1)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.4.0)\n",
      "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.21)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install textsearch\n",
    "!pip install contractions\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "ctP-qx30YUyC",
    "outputId": "9c44f887-e136-4d6f-ade2-d99bc090f7e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 20 columns):\n",
      "budget                  4803 non-null int64\n",
      "genres                  4803 non-null object\n",
      "homepage                1712 non-null object\n",
      "id                      4803 non-null int64\n",
      "keywords                4803 non-null object\n",
      "original_language       4803 non-null object\n",
      "original_title          4803 non-null object\n",
      "overview                4800 non-null object\n",
      "popularity              4803 non-null float64\n",
      "production_companies    4803 non-null object\n",
      "production_countries    4803 non-null object\n",
      "release_date            4802 non-null object\n",
      "revenue                 4803 non-null int64\n",
      "runtime                 4801 non-null float64\n",
      "spoken_languages        4803 non-null object\n",
      "status                  4803 non-null object\n",
      "tagline                 3959 non-null object\n",
      "title                   4803 non-null object\n",
      "vote_average            4803 non-null float64\n",
      "vote_count              4803 non-null int64\n",
      "dtypes: float64(3), int64(4), object(13)\n",
      "memory usage: 750.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2010%20-%20Project%208%20-%20Movie%20Recommendations%20with%20Document%20Similarity/tmdb_5000_movies.csv.gz', compression='gzip')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "frQbM_zrZC2D",
    "outputId": "928a694e-535e-44f3-8511-09e6aaa970d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget  ... vote_count\n",
       "0  237000000  ...      11800\n",
       "1  300000000  ...       4500\n",
       "2  245000000  ...       4466\n",
       "3  250000000  ...       9106\n",
       "4  260000000  ...       2124\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "2lURVWdjZGHL",
    "outputId": "80b0a7c4-db94-4831-d630-ad942194e150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4800 entries, 546 to 4553\n",
      "Data columns (total 5 columns):\n",
      "title          4800 non-null object\n",
      "tagline        4800 non-null object\n",
      "overview       4800 non-null object\n",
      "popularity     4800 non-null float64\n",
      "description    4800 non-null object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 225.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[['title', 'tagline', 'overview', 'popularity']]\n",
    "df.tagline.fillna('', inplace=True)\n",
    "df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
    "df.dropna(inplace=True)\n",
    "df = df.sort_values(by=['popularity'], ascending=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "hfwvf3UgZJK6",
    "outputId": "1cc6ff9f-d2ca-4c2f-d3e9-882a919588a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tagline</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Minions</td>\n",
       "      <td>Before Gru, they had a history of bad bosses</td>\n",
       "      <td>Minions Stuart, Kevin and Bob are recruited by...</td>\n",
       "      <td>875.581305</td>\n",
       "      <td>Before Gru, they had a history of bad bosses M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "      <td>Interstellar chronicles the adventures of a gr...</td>\n",
       "      <td>724.247784</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Witness the beginning of a happy ending</td>\n",
       "      <td>Deadpool tells the origin story of former Spec...</td>\n",
       "      <td>514.569956</td>\n",
       "      <td>Witness the beginning of a happy ending Deadpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>All heroes start somewhere.</td>\n",
       "      <td>Light years from Earth, 26 years after being a...</td>\n",
       "      <td>481.098624</td>\n",
       "      <td>All heroes start somewhere. Light years from E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>What a Lovely Day.</td>\n",
       "      <td>An apocalyptic story set in the furthest reach...</td>\n",
       "      <td>434.278564</td>\n",
       "      <td>What a Lovely Day. An apocalyptic story set in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  ...                                        description\n",
       "546                  Minions  ...  Before Gru, they had a history of bad bosses M...\n",
       "95              Interstellar  ...  Mankind was born on Earth. It was never meant ...\n",
       "788                 Deadpool  ...  Witness the beginning of a happy ending Deadpo...\n",
       "94   Guardians of the Galaxy  ...  All heroes start somewhere. Light years from E...\n",
       "127       Mad Max: Fury Road  ...  What a Lovely Day. An apocalyptic story set in...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wDHsF6qZWNv"
   },
   "source": [
    "# Build a Movie Recommender System\n",
    "\n",
    "Here you will build your own movie recommender system. We will use the following pipeline:\n",
    "- Text pre-processing\n",
    "- Feature Engineering\n",
    "- Document Similarity Computation\n",
    "- Find top similar movies\n",
    "- Build a movie recommendation function\n",
    "\n",
    "\n",
    "## Document Similarity\n",
    "\n",
    "Recommendations are about understanding the underlying features which make us favour one choice over the other. Similarity between items(in this case movies) is one way to understanding why we choose one movie over another. There are different ways to calculate similarity between two items. One of the most widely used measures is __cosine similarity__ which we have already used in the previous unit.\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "Cosine Similarity is used to calculate a numeric score to denote the similarity between two text documents. Mathematically, it is defined as follows:\n",
    "\n",
    "$$ cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BjLTJDE9ZXSj",
    "outputId": "e5fc7bae-a314-4d71-c9bc-ad9abc71c3ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    #filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNiwar7saOuj"
   },
   "source": [
    "## Extract TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NZkWolSnaRkd",
    "outputId": "3e0a37df-7289-4310-bae3-ff89f9cfd2a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 20468)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIyXn448aXnt"
   },
   "source": [
    "## Compute Pairwise Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "dKYgrUc4aUHm",
    "outputId": "54d2aec2-26c6-456f-ad7d-a7c87a6bb2c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>4760</th>\n",
       "      <th>4761</th>\n",
       "      <th>4762</th>\n",
       "      <th>4763</th>\n",
       "      <th>4764</th>\n",
       "      <th>4765</th>\n",
       "      <th>4766</th>\n",
       "      <th>4767</th>\n",
       "      <th>4768</th>\n",
       "      <th>4769</th>\n",
       "      <th>4770</th>\n",
       "      <th>4771</th>\n",
       "      <th>4772</th>\n",
       "      <th>4773</th>\n",
       "      <th>4774</th>\n",
       "      <th>4775</th>\n",
       "      <th>4776</th>\n",
       "      <th>4777</th>\n",
       "      <th>4778</th>\n",
       "      <th>4779</th>\n",
       "      <th>4780</th>\n",
       "      <th>4781</th>\n",
       "      <th>4782</th>\n",
       "      <th>4783</th>\n",
       "      <th>4784</th>\n",
       "      <th>4785</th>\n",
       "      <th>4786</th>\n",
       "      <th>4787</th>\n",
       "      <th>4788</th>\n",
       "      <th>4789</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050976</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.053475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034092</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008885</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019548</td>\n",
       "      <td>0.020365</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.028467</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027126</td>\n",
       "      <td>0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.017893</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060846</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036237</td>\n",
       "      <td>0.030516</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00607</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036611</td>\n",
       "      <td>0.023879</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028521</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.022974</td>\n",
       "      <td>0.054142</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.030759</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027018</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008650</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022056</td>\n",
       "      <td>0.019659</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076022</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.043469</td>\n",
       "      <td>0.011464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2     ...      4797      4798      4799\n",
       "0  1.00000  0.000000  0.000000  ...  0.000000  0.000000  0.009646\n",
       "1  0.00000  1.000000  0.000000  ...  0.000000  0.000000  0.007963\n",
       "2  0.00000  0.000000  1.000000  ...  0.000000  0.027126  0.009340\n",
       "3  0.00000  0.017839  0.000000  ...  0.000000  0.000000  0.000000\n",
       "4  0.00607  0.007967  0.017176  ...  0.004515  0.043469  0.011464\n",
       "\n",
       "[5 rows x 4800 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h08MqvY9adgt"
   },
   "source": [
    "## Get List of Movie Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rWr6lgqTaZsJ",
    "outputId": "1dd7e252-7493-4050-ea34-38cf5ae80327"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Minions', 'Interstellar', 'Deadpool', ..., 'Penitentiary',\n",
       "        'Alien Zone', 'America Is Still the Place'], dtype=object), (4800,))"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list = df['title'].values\n",
    "movies_list, movies_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69SKx3ZTaftu"
   },
   "source": [
    "## Find Top Similar Movies for a Sample Movie\n",
    "\n",
    "Let's take __Minions__ the most popular movie the the dataframe above and try and find the most similar movies which can be recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT3tw7Wka6B0"
   },
   "source": [
    "#### Find movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MmAUpmxWa-Kv",
    "outputId": "32b7417a-d1f5-4c65-f11f-1f911bd0fd2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_idx = np.where(movies_list == 'Minions')[0][0]\n",
    "movie_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IO3VhLka_vi"
   },
   "source": [
    "#### Get movie similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Shbop-mDbDSS",
    "outputId": "37299a9a-f003-43c3-f0ab-05fc04d00fd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "       0.00964634])"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_similarities = doc_sim_df.iloc[movie_idx].values\n",
    "movie_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjMx8FqtbE4O"
   },
   "source": [
    "#### Get top 5 similar movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AgmQgy8QbHDF",
    "outputId": "9d8c01e7-c8bb-41e4-9586-ecb7c4125d8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33,  60, 737, 490, 298])"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "similar_movie_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7Fzp3qcbJv3"
   },
   "source": [
    "#### Get top 5 similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "h4o7WpNlbNlT",
    "outputId": "1988d714-a5a9-43a2-ef58-e0ffa1499f34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Despicable Me 2', 'Despicable Me',\n",
       "       'Teenage Mutant Ninja Turtles: Out of the Shadows', 'Superman',\n",
       "       'Rise of the Guardians'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies = movies_list[similar_movie_idxs]\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5lpIbnMcnOx"
   },
   "source": [
    "### Build a movie recommender function to recommend top 5 similar movies for any movie \n",
    "\n",
    "The movie title, movie title list and document similarity matrix dataframe will be given as inputs to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOL8nLbacpXq"
   },
   "outputs": [],
   "source": [
    "def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df):\n",
    "    # find movie id\n",
    "    movie_idx = np.where(movies == movie_title)[0][0]\n",
    "    # get movie similarities\n",
    "    movie_similarities = doc_sims.iloc[movie_idx].values\n",
    "    # get top 5 similar movie IDs\n",
    "    similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "    # get top 5 movies\n",
    "    similar_movies = movies[similar_movie_idxs]\n",
    "    # return the top 5 movies\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4t4wBWwceFA"
   },
   "source": [
    "# Get popular Movie Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5V4EpMgAbPYY"
   },
   "outputs": [],
   "source": [
    "popular_movies = ['Minions', 'Interstellar', 'Deadpool', 'Jurassic World', 'Pirates of the Caribbean: The Curse of the Black Pearl',\n",
    "              'Dawn of the Planet of the Apes', 'The Hunger Games: Mockingjay - Part 1', 'Terminator Genisys', \n",
    "              'Captain America: Civil War', 'The Dark Knight', 'The Martian', 'Batman v Superman: Dawn of Justice', \n",
    "              'Pulp Fiction', 'The Godfather', 'The Shawshank Redemption', 'The Lord of the Rings: The Fellowship of the Ring',  \n",
    "              'Harry Potter and the Chamber of Secrets', 'Star Wars', 'The Hobbit: The Battle of the Five Armies',\n",
    "              'Iron Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N1ky8g-Ichp6",
    "outputId": "1baa39a7-3ded-45f5-9bf4-280de312acca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n",
      "Top 5 recommended Movies: ['Despicable Me 2' 'Despicable Me'\n",
      " 'Teenage Mutant Ninja Turtles: Out of the Shadows' 'Superman'\n",
      " 'Rise of the Guardians']\n",
      "\n",
      "Movie: Interstellar\n",
      "Top 5 recommended Movies: ['Gattaca' 'Space Pirate Captain Harlock' 'Space Cowboys'\n",
      " 'Starship Troopers' 'Final Destination 2']\n",
      "\n",
      "Movie: Deadpool\n",
      "Top 5 recommended Movies: ['Silent Trigger' 'Underworld: Evolution' 'Bronson' 'Shaft' 'Don Jon']\n",
      "\n",
      "Movie: Jurassic World\n",
      "Top 5 recommended Movies: ['Jurassic Park' 'The Lost World: Jurassic Park'\n",
      " \"National Lampoon's Vacation\" 'The Nut Job' 'Vacation']\n",
      "\n",
      "Movie: Pirates of the Caribbean: The Curse of the Black Pearl\n",
      "Top 5 recommended Movies: [\"Pirates of the Caribbean: Dead Man's Chest\"\n",
      " 'Pirates of the Caribbean: On Stranger Tides' 'The Pirate'\n",
      " 'The Pirates! In an Adventure with Scientists!' 'Joyful Noise']\n",
      "\n",
      "Movie: Dawn of the Planet of the Apes\n",
      "Top 5 recommended Movies: ['Battle for the Planet of the Apes' 'Groove' 'The Other End of the Line'\n",
      " 'Chicago Overcoat' 'Definitely, Maybe']\n",
      "\n",
      "Movie: The Hunger Games: Mockingjay - Part 1\n",
      "Top 5 recommended Movies: ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
      " 'John Carter' 'For Greater Glory - The True Story of Cristiada'\n",
      " 'The Proposition']\n",
      "\n",
      "Movie: Terminator Genisys\n",
      "Top 5 recommended Movies: ['Terminator 2: Judgment Day' 'Terminator Salvation'\n",
      " 'Terminator 3: Rise of the Machines' 'Mad Max'\n",
      " 'X-Men: Days of Future Past']\n",
      "\n",
      "Movie: Captain America: Civil War\n",
      "Top 5 recommended Movies: ['Captain America: The Winter Soldier' 'This Means War'\n",
      " 'Avengers: Age of Ultron' 'Iron Man 2' 'Escape from Tomorrow']\n",
      "\n",
      "Movie: The Dark Knight\n",
      "Top 5 recommended Movies: ['The Dark Knight Rises' 'Batman Forever' 'Batman Returns'\n",
      " 'Batman: The Dark Knight Returns, Part 2' 'JFK']\n",
      "\n",
      "Movie: The Martian\n",
      "Top 5 recommended Movies: ['The Last Days on Mars' 'Swept Away' 'Alive' 'All Is Lost' 'Red Planet']\n",
      "\n",
      "Movie: Batman v Superman: Dawn of Justice\n",
      "Top 5 recommended Movies: ['Batman Returns' 'The Punisher' 'Defendor'\n",
      " 'Batman: The Dark Knight Returns, Part 2' 'Nowhere to Run']\n",
      "\n",
      "Movie: Pulp Fiction\n",
      "Top 5 recommended Movies: ['Sliding Doors' 'You Kill Me' 'New York Stories' 'Timecrimes'\n",
      " 'All or Nothing']\n",
      "\n",
      "Movie: The Godfather\n",
      "Top 5 recommended Movies: ['The Godfather: Part II' 'Blood Ties' 'Made' 'Lords of London'\n",
      " 'Easy Money']\n",
      "\n",
      "Movie: The Shawshank Redemption\n",
      "Top 5 recommended Movies: ['Civil Brand' 'Les Misérables' 'The Chorus' 'Prison' 'Fortress']\n",
      "\n",
      "Movie: The Lord of the Rings: The Fellowship of the Ring\n",
      "Top 5 recommended Movies: ['The Lord of the Rings: The Two Towers'\n",
      " 'The Hobbit: The Desolation of Smaug'\n",
      " 'The Lord of the Rings: The Return of the King'\n",
      " \"What's the Worst That Could Happen?\" 'The Hobbit: An Unexpected Journey']\n",
      "\n",
      "Movie: Harry Potter and the Chamber of Secrets\n",
      "Top 5 recommended Movies: ['Harry Potter and the Prisoner of Azkaban'\n",
      " 'Harry Potter and the Goblet of Fire'\n",
      " 'Harry Potter and the Order of the Phoenix'\n",
      " 'Harry Potter and the Half-Blood Prince'\n",
      " \"Harry Potter and the Philosopher's Stone\"]\n",
      "\n",
      "Movie: Star Wars\n",
      "Top 5 recommended Movies: ['The Empire Strikes Back' 'Return of the Jedi' 'Shrek the Third'\n",
      " 'The Ice Pirates' 'The Tale of Despereaux']\n",
      "\n",
      "Movie: The Hobbit: The Battle of the Five Armies\n",
      "Top 5 recommended Movies: ['The Hobbit: The Desolation of Smaug' 'The Hobbit: An Unexpected Journey'\n",
      " \"Dragon Nest: Warriors' Dawn\"\n",
      " 'A Funny Thing Happened on the Way to the Forum' 'X-Men: Apocalypse']\n",
      "\n",
      "Movie: Iron Man\n",
      "Top 5 recommended Movies: ['Iron Man 2' 'Avengers: Age of Ultron' 'Hostage' 'Iron Man 3'\n",
      " 'Baahubali: The Beginning']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation with Embeddings\n",
    "\n",
    "We used count based normalized features in the previous section. Can we use word embeddings and then compute movie similarity? We definitely can! Here we will use the FastText model and train it on our corpus.\n",
    "\n",
    "The FastText model was first introduced by Facebook in 2016 as an extension and supposedly improvement of the vanilla Word2Vec model. Based on the original paper titled ‘Enriching Word Vectors with Subword Information’ by Mikolov et al. which is an excellent read to gain an in-depth understanding of how this model works. Overall, FastText is a framework for learning word representations and also performing robust, fast and accurate text classification. The framework is open-sourced by Facebook on GitHub and claims to have the following.\n",
    "- Recent state-of-the-art English word vectors.\n",
    "- Word vectors for 157 languages trained on Wikipedia and Crawl.\n",
    "- Models for language identification and various supervised tasks.\n",
    "\n",
    "Though I haven’t implemented this model from scratch, based on the research paper, following is what I learnt about how the model works. In general, predictive models like the Word2Vec model typically considers each word as a distinct entity (e.g. `where`) and generates a dense embedding for the word. However this poses to be a serious limitation with languages having massive vocabularies and many rare words which may not occur a lot in different corpora. The Word2Vec model typically ignores the morphological structure of each word and considers a word as a single entity. The FastText model considers each word as a Bag of Character n-grams. This is also called as a subword model in the paper.\n",
    "\n",
    "We add special boundary symbols < and > at the beginning and end of words. This enables us to distinguish prefixes and suffixes from other character sequences. We also include the word w itself in the set of its n-grams, to learn a representation for each word (in addition to its character n-grams). Taking the word `where` and n=3 (tri-grams) as an example, it will be represented by the character n-grams: `<wh, whe, her, ere, re>` and the special sequence `<where>` representing the whole word. Note that the sequence , corresponding to the word `<her>` is different from the tri-gram `her` from the word `where`.\n",
    "\n",
    "Here we leverage `gensim` to build our embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-uTK-ovctOw"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "tokenized_docs = [doc.split() for doc in norm_corpus]\n",
    "ft_model = FastText(tokenized_docs, size=300, window=30, min_count=2, workers=4, sg=1, iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate document level embeddings\n",
    "\n",
    "Word embedding models give us an embedding for each word, how can we use it for downstream ML\\DL tasks? one way is to flatten it or use sequential models. A simpler approach is to average all word embeddings for words in a document and generate a fixed-length document level emebdding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Te0xZdxFfXkK"
   },
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model.wv[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "        return feature_vector\n",
    "\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WhYLq48zf9mq",
    "outputId": "8756113e-c805-443c-a181-b01eea7456e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 300)"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vecs_ft = averaged_word2vec_vectorizer(tokenized_docs, ft_model, 300)\n",
    "doc_vecs_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Movie Recommendations\n",
    "\n",
    "We will leverage cosine similarity again to generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "-RQYRBoChXLb",
    "outputId": "dfea749a-cbea-486a-b0c9-b6cc65fb7841"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>4760</th>\n",
       "      <th>4761</th>\n",
       "      <th>4762</th>\n",
       "      <th>4763</th>\n",
       "      <th>4764</th>\n",
       "      <th>4765</th>\n",
       "      <th>4766</th>\n",
       "      <th>4767</th>\n",
       "      <th>4768</th>\n",
       "      <th>4769</th>\n",
       "      <th>4770</th>\n",
       "      <th>4771</th>\n",
       "      <th>4772</th>\n",
       "      <th>4773</th>\n",
       "      <th>4774</th>\n",
       "      <th>4775</th>\n",
       "      <th>4776</th>\n",
       "      <th>4777</th>\n",
       "      <th>4778</th>\n",
       "      <th>4779</th>\n",
       "      <th>4780</th>\n",
       "      <th>4781</th>\n",
       "      <th>4782</th>\n",
       "      <th>4783</th>\n",
       "      <th>4784</th>\n",
       "      <th>4785</th>\n",
       "      <th>4786</th>\n",
       "      <th>4787</th>\n",
       "      <th>4788</th>\n",
       "      <th>4789</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.492664</td>\n",
       "      <td>0.496308</td>\n",
       "      <td>0.510912</td>\n",
       "      <td>0.535769</td>\n",
       "      <td>0.500320</td>\n",
       "      <td>0.486901</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.403828</td>\n",
       "      <td>0.481371</td>\n",
       "      <td>0.516654</td>\n",
       "      <td>0.556541</td>\n",
       "      <td>0.515398</td>\n",
       "      <td>0.511148</td>\n",
       "      <td>0.480202</td>\n",
       "      <td>0.494923</td>\n",
       "      <td>0.499225</td>\n",
       "      <td>0.556211</td>\n",
       "      <td>0.480949</td>\n",
       "      <td>0.479091</td>\n",
       "      <td>0.479232</td>\n",
       "      <td>0.553309</td>\n",
       "      <td>0.537978</td>\n",
       "      <td>0.536106</td>\n",
       "      <td>0.556041</td>\n",
       "      <td>0.501698</td>\n",
       "      <td>0.491527</td>\n",
       "      <td>0.524758</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.552796</td>\n",
       "      <td>0.495750</td>\n",
       "      <td>0.532899</td>\n",
       "      <td>0.503712</td>\n",
       "      <td>0.668022</td>\n",
       "      <td>0.486572</td>\n",
       "      <td>0.539664</td>\n",
       "      <td>0.579454</td>\n",
       "      <td>0.452427</td>\n",
       "      <td>0.489803</td>\n",
       "      <td>0.569999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539699</td>\n",
       "      <td>0.580656</td>\n",
       "      <td>0.486330</td>\n",
       "      <td>0.503779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520268</td>\n",
       "      <td>0.431107</td>\n",
       "      <td>0.528245</td>\n",
       "      <td>0.401787</td>\n",
       "      <td>0.491489</td>\n",
       "      <td>0.490939</td>\n",
       "      <td>0.579464</td>\n",
       "      <td>0.454055</td>\n",
       "      <td>0.521494</td>\n",
       "      <td>0.451900</td>\n",
       "      <td>0.464359</td>\n",
       "      <td>0.480017</td>\n",
       "      <td>0.433644</td>\n",
       "      <td>0.467632</td>\n",
       "      <td>0.486388</td>\n",
       "      <td>0.538019</td>\n",
       "      <td>0.470559</td>\n",
       "      <td>0.343202</td>\n",
       "      <td>0.567069</td>\n",
       "      <td>0.505675</td>\n",
       "      <td>0.494155</td>\n",
       "      <td>0.518892</td>\n",
       "      <td>0.514991</td>\n",
       "      <td>0.496923</td>\n",
       "      <td>0.537625</td>\n",
       "      <td>0.557840</td>\n",
       "      <td>0.454287</td>\n",
       "      <td>0.579657</td>\n",
       "      <td>0.473208</td>\n",
       "      <td>0.513137</td>\n",
       "      <td>0.475539</td>\n",
       "      <td>0.532357</td>\n",
       "      <td>0.474379</td>\n",
       "      <td>0.518188</td>\n",
       "      <td>0.551425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.492664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.563403</td>\n",
       "      <td>0.545177</td>\n",
       "      <td>0.603489</td>\n",
       "      <td>0.517669</td>\n",
       "      <td>0.505453</td>\n",
       "      <td>0.584717</td>\n",
       "      <td>0.489141</td>\n",
       "      <td>0.527009</td>\n",
       "      <td>0.575785</td>\n",
       "      <td>0.579353</td>\n",
       "      <td>0.513444</td>\n",
       "      <td>0.493603</td>\n",
       "      <td>0.653348</td>\n",
       "      <td>0.457902</td>\n",
       "      <td>0.533790</td>\n",
       "      <td>0.570331</td>\n",
       "      <td>0.604212</td>\n",
       "      <td>0.515493</td>\n",
       "      <td>0.481409</td>\n",
       "      <td>0.581974</td>\n",
       "      <td>0.556100</td>\n",
       "      <td>0.514275</td>\n",
       "      <td>0.575213</td>\n",
       "      <td>0.494131</td>\n",
       "      <td>0.497962</td>\n",
       "      <td>0.573492</td>\n",
       "      <td>0.594617</td>\n",
       "      <td>0.615781</td>\n",
       "      <td>0.546663</td>\n",
       "      <td>0.569933</td>\n",
       "      <td>0.533180</td>\n",
       "      <td>0.466352</td>\n",
       "      <td>0.505694</td>\n",
       "      <td>0.589641</td>\n",
       "      <td>0.598830</td>\n",
       "      <td>0.463351</td>\n",
       "      <td>0.523948</td>\n",
       "      <td>0.600930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540858</td>\n",
       "      <td>0.582376</td>\n",
       "      <td>0.641514</td>\n",
       "      <td>0.541945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560510</td>\n",
       "      <td>0.490818</td>\n",
       "      <td>0.561715</td>\n",
       "      <td>0.455354</td>\n",
       "      <td>0.535180</td>\n",
       "      <td>0.646578</td>\n",
       "      <td>0.576697</td>\n",
       "      <td>0.544990</td>\n",
       "      <td>0.559209</td>\n",
       "      <td>0.511443</td>\n",
       "      <td>0.455557</td>\n",
       "      <td>0.514441</td>\n",
       "      <td>0.466614</td>\n",
       "      <td>0.456843</td>\n",
       "      <td>0.523400</td>\n",
       "      <td>0.555628</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.285916</td>\n",
       "      <td>0.528488</td>\n",
       "      <td>0.503273</td>\n",
       "      <td>0.489853</td>\n",
       "      <td>0.549668</td>\n",
       "      <td>0.576395</td>\n",
       "      <td>0.451794</td>\n",
       "      <td>0.474446</td>\n",
       "      <td>0.560500</td>\n",
       "      <td>0.485316</td>\n",
       "      <td>0.552406</td>\n",
       "      <td>0.473985</td>\n",
       "      <td>0.572856</td>\n",
       "      <td>0.504204</td>\n",
       "      <td>0.491027</td>\n",
       "      <td>0.494966</td>\n",
       "      <td>0.523733</td>\n",
       "      <td>0.573146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.496308</td>\n",
       "      <td>0.563403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.578705</td>\n",
       "      <td>0.587129</td>\n",
       "      <td>0.470731</td>\n",
       "      <td>0.527420</td>\n",
       "      <td>0.515955</td>\n",
       "      <td>0.530370</td>\n",
       "      <td>0.581713</td>\n",
       "      <td>0.575859</td>\n",
       "      <td>0.554697</td>\n",
       "      <td>0.518732</td>\n",
       "      <td>0.511006</td>\n",
       "      <td>0.560594</td>\n",
       "      <td>0.490921</td>\n",
       "      <td>0.569978</td>\n",
       "      <td>0.550745</td>\n",
       "      <td>0.514001</td>\n",
       "      <td>0.514964</td>\n",
       "      <td>0.489199</td>\n",
       "      <td>0.542026</td>\n",
       "      <td>0.559439</td>\n",
       "      <td>0.499355</td>\n",
       "      <td>0.562130</td>\n",
       "      <td>0.569028</td>\n",
       "      <td>0.469616</td>\n",
       "      <td>0.526761</td>\n",
       "      <td>0.530578</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>0.567329</td>\n",
       "      <td>0.557099</td>\n",
       "      <td>0.544709</td>\n",
       "      <td>0.504860</td>\n",
       "      <td>0.561595</td>\n",
       "      <td>0.566932</td>\n",
       "      <td>0.533370</td>\n",
       "      <td>0.496736</td>\n",
       "      <td>0.572349</td>\n",
       "      <td>0.576454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575831</td>\n",
       "      <td>0.535931</td>\n",
       "      <td>0.534528</td>\n",
       "      <td>0.501722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520267</td>\n",
       "      <td>0.493430</td>\n",
       "      <td>0.571536</td>\n",
       "      <td>0.456092</td>\n",
       "      <td>0.552054</td>\n",
       "      <td>0.523101</td>\n",
       "      <td>0.577292</td>\n",
       "      <td>0.534820</td>\n",
       "      <td>0.537752</td>\n",
       "      <td>0.508964</td>\n",
       "      <td>0.444129</td>\n",
       "      <td>0.496698</td>\n",
       "      <td>0.511398</td>\n",
       "      <td>0.472164</td>\n",
       "      <td>0.472460</td>\n",
       "      <td>0.527869</td>\n",
       "      <td>0.528036</td>\n",
       "      <td>0.306630</td>\n",
       "      <td>0.535770</td>\n",
       "      <td>0.463161</td>\n",
       "      <td>0.466277</td>\n",
       "      <td>0.526613</td>\n",
       "      <td>0.540793</td>\n",
       "      <td>0.543037</td>\n",
       "      <td>0.538885</td>\n",
       "      <td>0.532356</td>\n",
       "      <td>0.526620</td>\n",
       "      <td>0.558509</td>\n",
       "      <td>0.463098</td>\n",
       "      <td>0.559336</td>\n",
       "      <td>0.536197</td>\n",
       "      <td>0.541042</td>\n",
       "      <td>0.525498</td>\n",
       "      <td>0.542619</td>\n",
       "      <td>0.545562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510912</td>\n",
       "      <td>0.545177</td>\n",
       "      <td>0.578705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.590060</td>\n",
       "      <td>0.511298</td>\n",
       "      <td>0.481921</td>\n",
       "      <td>0.511408</td>\n",
       "      <td>0.502355</td>\n",
       "      <td>0.536240</td>\n",
       "      <td>0.558474</td>\n",
       "      <td>0.557189</td>\n",
       "      <td>0.502109</td>\n",
       "      <td>0.495526</td>\n",
       "      <td>0.578293</td>\n",
       "      <td>0.544688</td>\n",
       "      <td>0.553659</td>\n",
       "      <td>0.573777</td>\n",
       "      <td>0.515629</td>\n",
       "      <td>0.485216</td>\n",
       "      <td>0.487369</td>\n",
       "      <td>0.557719</td>\n",
       "      <td>0.564870</td>\n",
       "      <td>0.551208</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>0.529047</td>\n",
       "      <td>0.432864</td>\n",
       "      <td>0.518734</td>\n",
       "      <td>0.492371</td>\n",
       "      <td>0.604807</td>\n",
       "      <td>0.511024</td>\n",
       "      <td>0.519564</td>\n",
       "      <td>0.524674</td>\n",
       "      <td>0.488336</td>\n",
       "      <td>0.494692</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.604437</td>\n",
       "      <td>0.476813</td>\n",
       "      <td>0.526082</td>\n",
       "      <td>0.575280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507219</td>\n",
       "      <td>0.501528</td>\n",
       "      <td>0.526166</td>\n",
       "      <td>0.586476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498878</td>\n",
       "      <td>0.406795</td>\n",
       "      <td>0.546657</td>\n",
       "      <td>0.413804</td>\n",
       "      <td>0.511191</td>\n",
       "      <td>0.510685</td>\n",
       "      <td>0.542662</td>\n",
       "      <td>0.456270</td>\n",
       "      <td>0.522375</td>\n",
       "      <td>0.541161</td>\n",
       "      <td>0.450507</td>\n",
       "      <td>0.524743</td>\n",
       "      <td>0.498713</td>\n",
       "      <td>0.474976</td>\n",
       "      <td>0.555518</td>\n",
       "      <td>0.577508</td>\n",
       "      <td>0.497237</td>\n",
       "      <td>0.347284</td>\n",
       "      <td>0.557203</td>\n",
       "      <td>0.526138</td>\n",
       "      <td>0.489007</td>\n",
       "      <td>0.557042</td>\n",
       "      <td>0.603214</td>\n",
       "      <td>0.483213</td>\n",
       "      <td>0.517395</td>\n",
       "      <td>0.532141</td>\n",
       "      <td>0.579059</td>\n",
       "      <td>0.592812</td>\n",
       "      <td>0.482258</td>\n",
       "      <td>0.547086</td>\n",
       "      <td>0.547431</td>\n",
       "      <td>0.567795</td>\n",
       "      <td>0.507392</td>\n",
       "      <td>0.502579</td>\n",
       "      <td>0.544799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.535769</td>\n",
       "      <td>0.603489</td>\n",
       "      <td>0.587129</td>\n",
       "      <td>0.590060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564680</td>\n",
       "      <td>0.569394</td>\n",
       "      <td>0.668452</td>\n",
       "      <td>0.559399</td>\n",
       "      <td>0.551341</td>\n",
       "      <td>0.595495</td>\n",
       "      <td>0.624358</td>\n",
       "      <td>0.540820</td>\n",
       "      <td>0.578923</td>\n",
       "      <td>0.663770</td>\n",
       "      <td>0.565360</td>\n",
       "      <td>0.650237</td>\n",
       "      <td>0.627029</td>\n",
       "      <td>0.643336</td>\n",
       "      <td>0.576168</td>\n",
       "      <td>0.553061</td>\n",
       "      <td>0.602179</td>\n",
       "      <td>0.648406</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>0.585841</td>\n",
       "      <td>0.527725</td>\n",
       "      <td>0.493498</td>\n",
       "      <td>0.618335</td>\n",
       "      <td>0.607178</td>\n",
       "      <td>0.673672</td>\n",
       "      <td>0.564068</td>\n",
       "      <td>0.625221</td>\n",
       "      <td>0.639371</td>\n",
       "      <td>0.555308</td>\n",
       "      <td>0.623144</td>\n",
       "      <td>0.604440</td>\n",
       "      <td>0.644364</td>\n",
       "      <td>0.536808</td>\n",
       "      <td>0.646316</td>\n",
       "      <td>0.608405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588222</td>\n",
       "      <td>0.570244</td>\n",
       "      <td>0.647099</td>\n",
       "      <td>0.573426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.584451</td>\n",
       "      <td>0.534608</td>\n",
       "      <td>0.597488</td>\n",
       "      <td>0.437698</td>\n",
       "      <td>0.543725</td>\n",
       "      <td>0.628278</td>\n",
       "      <td>0.620133</td>\n",
       "      <td>0.581030</td>\n",
       "      <td>0.610563</td>\n",
       "      <td>0.598553</td>\n",
       "      <td>0.538588</td>\n",
       "      <td>0.581358</td>\n",
       "      <td>0.558789</td>\n",
       "      <td>0.581866</td>\n",
       "      <td>0.610934</td>\n",
       "      <td>0.593388</td>\n",
       "      <td>0.577401</td>\n",
       "      <td>0.352316</td>\n",
       "      <td>0.604340</td>\n",
       "      <td>0.580486</td>\n",
       "      <td>0.548577</td>\n",
       "      <td>0.627801</td>\n",
       "      <td>0.571301</td>\n",
       "      <td>0.592933</td>\n",
       "      <td>0.550137</td>\n",
       "      <td>0.632155</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>0.642776</td>\n",
       "      <td>0.443999</td>\n",
       "      <td>0.616751</td>\n",
       "      <td>0.536856</td>\n",
       "      <td>0.642225</td>\n",
       "      <td>0.572681</td>\n",
       "      <td>0.649322</td>\n",
       "      <td>0.628217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2     ...      4797      4798      4799\n",
       "0  1.000000  0.492664  0.496308  ...  0.474379  0.518188  0.551425\n",
       "1  0.492664  1.000000  0.563403  ...  0.494966  0.523733  0.573146\n",
       "2  0.496308  0.563403  1.000000  ...  0.525498  0.542619  0.545562\n",
       "3  0.510912  0.545177  0.578705  ...  0.507392  0.502579  0.544799\n",
       "4  0.535769  0.603489  0.587129  ...  0.572681  0.649322  0.628217\n",
       "\n",
       "[5 rows x 4800 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim = cosine_similarity(doc_vecs_ft)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SM-fGDVvgcuX",
    "outputId": "e4c5a452-a91b-4b20-a925-90fefc69d5d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n",
      "Top 5 recommended Movies: ['Despicable Me' 'Time Bandits'\n",
      " 'Rise of the Entrepreneur: The Search for a Better Way'\n",
      " 'Austin Powers: The Spy Who Shagged Me' 'Despicable Me 2']\n",
      "\n",
      "Movie: Interstellar\n",
      "Top 5 recommended Movies: ['Gattaca' 'Prometheus' 'The Cave'\n",
      " 'Sea Rex 3D: Journey to a Prehistoric World' 'Space Cowboys']\n",
      "\n",
      "Movie: Deadpool\n",
      "Top 5 recommended Movies: ['Fantastic Four' 'Banshee Chapter' 'Spider-Man 3' 'Enough' 'Spider-Man 2']\n",
      "\n",
      "Movie: Jurassic World\n",
      "Top 5 recommended Movies: ['Jurassic Park' 'Jurassic Park III' 'The Lost World: Jurassic Park'\n",
      " \"National Lampoon's Vacation\" 'Walking With Dinosaurs']\n",
      "\n",
      "Movie: Pirates of the Caribbean: The Curse of the Black Pearl\n",
      "Top 5 recommended Movies: ['Pirates of the Caribbean: On Stranger Tides'\n",
      " 'The Pirates! In an Adventure with Scientists!'\n",
      " \"Pirates of the Caribbean: Dead Man's Chest\"\n",
      " 'American Ninja 2: The Confrontation' 'In the Name of the King III']\n",
      "\n",
      "Movie: Dawn of the Planet of the Apes\n",
      "Top 5 recommended Movies: ['Battle for the Planet of the Apes' 'Conquest of the Planet of the Apes'\n",
      " 'Planet of the Apes' 'Rise of the Planet of the Apes'\n",
      " 'Beneath the Planet of the Apes']\n",
      "\n",
      "Movie: The Hunger Games: Mockingjay - Part 1\n",
      "Top 5 recommended Movies: ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
      " 'The Hunger Games' 'White House Down' 'Pieces of April']\n",
      "\n",
      "Movie: Terminator Genisys\n",
      "Top 5 recommended Movies: ['Terminator 2: Judgment Day' 'Terminator 3: Rise of the Machines'\n",
      " 'Terminator Salvation' 'X-Men: Days of Future Past' 'The Terminator']\n",
      "\n",
      "Movie: Captain America: Civil War\n",
      "Top 5 recommended Movies: ['Captain America: The Winter Soldier' 'Avengers: Age of Ultron'\n",
      " 'Iron Man 2' 'Divergent' 'Star Trek Into Darkness']\n",
      "\n",
      "Movie: The Dark Knight\n",
      "Top 5 recommended Movies: ['The Dark Knight Rises' 'Batman Forever' 'Batman Returns' 'Batman'\n",
      " 'Batman: The Dark Knight Returns, Part 2']\n",
      "\n",
      "Movie: The Martian\n",
      "Top 5 recommended Movies: ['Battleship' 'Red Planet' 'Sanctum' 'Alien'\n",
      " 'Star Trek IV: The Voyage Home']\n",
      "\n",
      "Movie: Batman v Superman: Dawn of Justice\n",
      "Top 5 recommended Movies: ['Defendor' 'Batman: The Dark Knight Returns, Part 2' 'Batman Returns'\n",
      " 'Batman' 'The Dark Knight Rises']\n",
      "\n",
      "Movie: Pulp Fiction\n",
      "Top 5 recommended Movies: ['Locker 13' 'Sliding Doors' '11:14' 'Crying with Laughter' 'The Sting']\n",
      "\n",
      "Movie: The Godfather\n",
      "Top 5 recommended Movies: ['The Godfather: Part II' 'The Godfather: Part III' 'Loose Cannons'\n",
      " 'Machete' 'The Jerky Boys']\n",
      "\n",
      "Movie: The Shawshank Redemption\n",
      "Top 5 recommended Movies: ['Civil Brand' 'Prison' 'Escape Plan' 'Bridge of Spies' 'Get Hard']\n",
      "\n",
      "Movie: The Lord of the Rings: The Fellowship of the Ring\n",
      "Top 5 recommended Movies: ['The Lord of the Rings: The Two Towers'\n",
      " 'The Hobbit: An Unexpected Journey' 'The Hobbit: The Desolation of Smaug'\n",
      " 'The Lord of the Rings: The Return of the King'\n",
      " 'The Hobbit: The Battle of the Five Armies']\n",
      "\n",
      "Movie: Harry Potter and the Chamber of Secrets\n",
      "Top 5 recommended Movies: ['Harry Potter and the Goblet of Fire'\n",
      " 'Harry Potter and the Prisoner of Azkaban'\n",
      " 'Harry Potter and the Order of the Phoenix'\n",
      " 'Harry Potter and the Half-Blood Prince'\n",
      " \"Harry Potter and the Philosopher's Stone\"]\n",
      "\n",
      "Movie: Star Wars\n",
      "Top 5 recommended Movies: ['The Empire Strikes Back' 'Return of the Jedi'\n",
      " 'Star Wars: Episode III - Revenge of the Sith'\n",
      " 'Star Wars: Episode II - Attack of the Clones' 'The Ice Pirates']\n",
      "\n",
      "Movie: The Hobbit: The Battle of the Five Armies\n",
      "Top 5 recommended Movies: ['The Hobbit: The Desolation of Smaug' 'The Hobbit: An Unexpected Journey'\n",
      " \"Dragon Nest: Warriors' Dawn\" '300: Rise of an Empire'\n",
      " 'Battle for the Planet of the Apes']\n",
      "\n",
      "Movie: Iron Man\n",
      "Top 5 recommended Movies: ['Iron Man 2' 'Avengers: Age of Ultron' 'Batman Begins' 'Iron Man 3'\n",
      " 'Steel']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with ELMO pre-trained embeddings\n",
    "\n",
    "ELMo is a novel way to represent documents\\words as embeddings with more contextual information. These embeddings are helpful in achieving state-of-the-art (SOTA) results in several NLP tasks. \n",
    "\n",
    "![](https://i.imgur.com/pqHFUeE.gif)\n",
    "\n",
    "ELMo word vectors are computed on top of a two-layer bidirectional language model. The model has two layers stacked together (e.g sequential models like LSTMs). Each layer goes both forward and backward and concatenates the result states (or averages\\sums) to capture contextual information better. Just like bi-directional LSTMs\\GRUs we will be using later.\n",
    "\n",
    "- The architecture above uses a character-level convolutional neural network (CNN) to represent words of a text string into raw word vectors\n",
    "- These raw word vectors act as inputs to the first layer of the model\n",
    "- The forward pass contains information about a certain word and the context (other words) before that word\n",
    "- The backward pass contains information about the word and the context after it\n",
    "- This pair of information, from the forward and backward pass, forms the intermediate word vectors\n",
    "- These intermediate word vectors are fed into the next layer of biLM\n",
    "- The final representation (ELMo) is the weighted sum of the raw word vectors and the 2 intermediate word vectors\n",
    "\n",
    "Helps capture subword level information just like fasttext and also different context of same words based on their usage e.g: 'the _bank_ gives good interest' vs. 'i'm at the river _bank_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ELMo as a feature extractor\n",
    "\n",
    "Here we will be leveraging the pre-trained ELMo model as a feature extractor and extract document level 1024-sized embeddings for each our our movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-eq8c_Adhgs3"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "re4A4W7Bkhv9",
    "outputId": "f486f2b5-c25b-408d-dd8d-0e1ac0a784b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before Gru, they had a history of bad bosses Minions Stuart, Kevin and Bob are recruited by Scarlet Overkill, a super-villain who, alongside her inventor husband Herb, hatches a plot to take over the world.'"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_desc = df.iloc[0]['description']\n",
    "sample_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p3VJdVdykpO-",
    "outputId": "9415d877-40b9-4f62-a6ec-27182abdd4b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(35), Dimension(1024)])"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = elmo([sample_desc], signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbRKb6VNmawM"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    embeddings = elmo([sample_desc, 'hello how are you'], signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    a = (sess.run(tf.reduce_mean(embeddings,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCExR2YQk6vP"
   },
   "outputs": [],
   "source": [
    "def get_elmo_embeddings(docs, batch_size=32):\n",
    "  elmo_embeddings = []\n",
    "  i = 0\n",
    "  total_docs = len(docs)\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    while i < total_docs:\n",
    "      i_new = i + batch_size\n",
    "      if i_new < len(docs):\n",
    "        embeddings = elmo(docs[i:i_new], signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "      else:\n",
    "        embeddings = elmo(docs[i:], signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "      i = i_new\n",
    "      elmo_embeddings.append(sess.run(tf.reduce_mean(embeddings,1)))\n",
    "    return np.concatenate(elmo_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QKeLxfeVlsrl",
    "outputId": "2a0cdb90-1c74-4e1d-cfa1-7be218413739"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 1024)"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_embeddings = get_elmo_embeddings(norm_corpus, batch_size=128)\n",
    "elmo_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Movie Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "eKpYDQSznXJd",
    "outputId": "cdd89c4e-ec0b-4d28-9b1b-9531d591535a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>4760</th>\n",
       "      <th>4761</th>\n",
       "      <th>4762</th>\n",
       "      <th>4763</th>\n",
       "      <th>4764</th>\n",
       "      <th>4765</th>\n",
       "      <th>4766</th>\n",
       "      <th>4767</th>\n",
       "      <th>4768</th>\n",
       "      <th>4769</th>\n",
       "      <th>4770</th>\n",
       "      <th>4771</th>\n",
       "      <th>4772</th>\n",
       "      <th>4773</th>\n",
       "      <th>4774</th>\n",
       "      <th>4775</th>\n",
       "      <th>4776</th>\n",
       "      <th>4777</th>\n",
       "      <th>4778</th>\n",
       "      <th>4779</th>\n",
       "      <th>4780</th>\n",
       "      <th>4781</th>\n",
       "      <th>4782</th>\n",
       "      <th>4783</th>\n",
       "      <th>4784</th>\n",
       "      <th>4785</th>\n",
       "      <th>4786</th>\n",
       "      <th>4787</th>\n",
       "      <th>4788</th>\n",
       "      <th>4789</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673902</td>\n",
       "      <td>0.751573</td>\n",
       "      <td>0.863714</td>\n",
       "      <td>0.689305</td>\n",
       "      <td>0.743295</td>\n",
       "      <td>0.787667</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.768811</td>\n",
       "      <td>0.798508</td>\n",
       "      <td>0.765984</td>\n",
       "      <td>0.738887</td>\n",
       "      <td>0.785630</td>\n",
       "      <td>0.764878</td>\n",
       "      <td>0.674737</td>\n",
       "      <td>0.744505</td>\n",
       "      <td>0.757085</td>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.739036</td>\n",
       "      <td>0.763905</td>\n",
       "      <td>0.846082</td>\n",
       "      <td>0.812291</td>\n",
       "      <td>0.711172</td>\n",
       "      <td>0.811894</td>\n",
       "      <td>0.737671</td>\n",
       "      <td>0.813584</td>\n",
       "      <td>0.752075</td>\n",
       "      <td>0.699435</td>\n",
       "      <td>0.780520</td>\n",
       "      <td>0.818098</td>\n",
       "      <td>0.691326</td>\n",
       "      <td>0.687013</td>\n",
       "      <td>0.810482</td>\n",
       "      <td>0.841995</td>\n",
       "      <td>0.742114</td>\n",
       "      <td>0.786964</td>\n",
       "      <td>0.729926</td>\n",
       "      <td>0.873464</td>\n",
       "      <td>0.790300</td>\n",
       "      <td>0.761930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760047</td>\n",
       "      <td>0.749157</td>\n",
       "      <td>0.602688</td>\n",
       "      <td>0.756960</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.582010</td>\n",
       "      <td>0.833129</td>\n",
       "      <td>0.782325</td>\n",
       "      <td>0.664777</td>\n",
       "      <td>0.775956</td>\n",
       "      <td>0.666539</td>\n",
       "      <td>0.773167</td>\n",
       "      <td>0.795130</td>\n",
       "      <td>0.663970</td>\n",
       "      <td>0.758077</td>\n",
       "      <td>0.756637</td>\n",
       "      <td>0.694812</td>\n",
       "      <td>0.728161</td>\n",
       "      <td>0.784195</td>\n",
       "      <td>0.800416</td>\n",
       "      <td>0.718451</td>\n",
       "      <td>0.816857</td>\n",
       "      <td>0.671299</td>\n",
       "      <td>0.725745</td>\n",
       "      <td>0.757803</td>\n",
       "      <td>0.793940</td>\n",
       "      <td>0.578746</td>\n",
       "      <td>0.622107</td>\n",
       "      <td>0.835142</td>\n",
       "      <td>0.737978</td>\n",
       "      <td>0.734108</td>\n",
       "      <td>0.867359</td>\n",
       "      <td>0.749411</td>\n",
       "      <td>0.796369</td>\n",
       "      <td>0.761055</td>\n",
       "      <td>0.787904</td>\n",
       "      <td>0.628688</td>\n",
       "      <td>0.720340</td>\n",
       "      <td>0.782287</td>\n",
       "      <td>0.690373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.635209</td>\n",
       "      <td>0.745993</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.647107</td>\n",
       "      <td>0.636410</td>\n",
       "      <td>0.726282</td>\n",
       "      <td>0.644014</td>\n",
       "      <td>0.639146</td>\n",
       "      <td>0.697943</td>\n",
       "      <td>0.696398</td>\n",
       "      <td>0.651200</td>\n",
       "      <td>0.619105</td>\n",
       "      <td>0.797880</td>\n",
       "      <td>0.676857</td>\n",
       "      <td>0.636756</td>\n",
       "      <td>0.652537</td>\n",
       "      <td>0.740867</td>\n",
       "      <td>0.625048</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.713823</td>\n",
       "      <td>0.672913</td>\n",
       "      <td>0.643272</td>\n",
       "      <td>0.661184</td>\n",
       "      <td>0.661125</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.609703</td>\n",
       "      <td>0.699224</td>\n",
       "      <td>0.672637</td>\n",
       "      <td>0.707378</td>\n",
       "      <td>0.702402</td>\n",
       "      <td>0.690226</td>\n",
       "      <td>0.627070</td>\n",
       "      <td>0.564022</td>\n",
       "      <td>0.665528</td>\n",
       "      <td>0.700463</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.804130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652133</td>\n",
       "      <td>0.548200</td>\n",
       "      <td>0.747544</td>\n",
       "      <td>0.546157</td>\n",
       "      <td>0.407826</td>\n",
       "      <td>0.547783</td>\n",
       "      <td>0.650193</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>0.509724</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.712193</td>\n",
       "      <td>0.674869</td>\n",
       "      <td>0.622215</td>\n",
       "      <td>0.561811</td>\n",
       "      <td>0.636012</td>\n",
       "      <td>0.555241</td>\n",
       "      <td>0.598729</td>\n",
       "      <td>0.627150</td>\n",
       "      <td>0.593192</td>\n",
       "      <td>0.582941</td>\n",
       "      <td>0.538249</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.470351</td>\n",
       "      <td>0.636928</td>\n",
       "      <td>0.591095</td>\n",
       "      <td>0.597366</td>\n",
       "      <td>0.497236</td>\n",
       "      <td>0.565199</td>\n",
       "      <td>0.587670</td>\n",
       "      <td>0.520422</td>\n",
       "      <td>0.631614</td>\n",
       "      <td>0.660010</td>\n",
       "      <td>0.591151</td>\n",
       "      <td>0.562878</td>\n",
       "      <td>0.644372</td>\n",
       "      <td>0.650457</td>\n",
       "      <td>0.471403</td>\n",
       "      <td>0.593951</td>\n",
       "      <td>0.613347</td>\n",
       "      <td>0.577721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.751573</td>\n",
       "      <td>0.635209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776931</td>\n",
       "      <td>0.812324</td>\n",
       "      <td>0.626358</td>\n",
       "      <td>0.805680</td>\n",
       "      <td>0.752336</td>\n",
       "      <td>0.636632</td>\n",
       "      <td>0.727761</td>\n",
       "      <td>0.827235</td>\n",
       "      <td>0.755048</td>\n",
       "      <td>0.666357</td>\n",
       "      <td>0.866802</td>\n",
       "      <td>0.750277</td>\n",
       "      <td>0.800741</td>\n",
       "      <td>0.838277</td>\n",
       "      <td>0.796359</td>\n",
       "      <td>0.696132</td>\n",
       "      <td>0.819026</td>\n",
       "      <td>0.670245</td>\n",
       "      <td>0.802342</td>\n",
       "      <td>0.800858</td>\n",
       "      <td>0.815696</td>\n",
       "      <td>0.807615</td>\n",
       "      <td>0.710225</td>\n",
       "      <td>0.641008</td>\n",
       "      <td>0.797783</td>\n",
       "      <td>0.644627</td>\n",
       "      <td>0.744030</td>\n",
       "      <td>0.741489</td>\n",
       "      <td>0.702317</td>\n",
       "      <td>0.806460</td>\n",
       "      <td>0.644382</td>\n",
       "      <td>0.846387</td>\n",
       "      <td>0.839317</td>\n",
       "      <td>0.829216</td>\n",
       "      <td>0.741464</td>\n",
       "      <td>0.730140</td>\n",
       "      <td>0.747999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737073</td>\n",
       "      <td>0.752865</td>\n",
       "      <td>0.696997</td>\n",
       "      <td>0.668742</td>\n",
       "      <td>0.262846</td>\n",
       "      <td>0.623608</td>\n",
       "      <td>0.700227</td>\n",
       "      <td>0.739211</td>\n",
       "      <td>0.431054</td>\n",
       "      <td>0.679432</td>\n",
       "      <td>0.676116</td>\n",
       "      <td>0.718834</td>\n",
       "      <td>0.651115</td>\n",
       "      <td>0.726430</td>\n",
       "      <td>0.610499</td>\n",
       "      <td>0.698294</td>\n",
       "      <td>0.629757</td>\n",
       "      <td>0.679335</td>\n",
       "      <td>0.596131</td>\n",
       "      <td>0.690085</td>\n",
       "      <td>0.783374</td>\n",
       "      <td>0.670873</td>\n",
       "      <td>0.354831</td>\n",
       "      <td>0.772638</td>\n",
       "      <td>0.717234</td>\n",
       "      <td>0.611620</td>\n",
       "      <td>0.769312</td>\n",
       "      <td>0.628364</td>\n",
       "      <td>0.679596</td>\n",
       "      <td>0.753085</td>\n",
       "      <td>0.811146</td>\n",
       "      <td>0.736430</td>\n",
       "      <td>0.779702</td>\n",
       "      <td>0.617341</td>\n",
       "      <td>0.767700</td>\n",
       "      <td>0.695560</td>\n",
       "      <td>0.753344</td>\n",
       "      <td>0.783749</td>\n",
       "      <td>0.799898</td>\n",
       "      <td>0.729796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863714</td>\n",
       "      <td>0.745993</td>\n",
       "      <td>0.776931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722593</td>\n",
       "      <td>0.751869</td>\n",
       "      <td>0.794865</td>\n",
       "      <td>0.839330</td>\n",
       "      <td>0.803945</td>\n",
       "      <td>0.777118</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.740758</td>\n",
       "      <td>0.772130</td>\n",
       "      <td>0.774399</td>\n",
       "      <td>0.749708</td>\n",
       "      <td>0.778072</td>\n",
       "      <td>0.771104</td>\n",
       "      <td>0.735786</td>\n",
       "      <td>0.809802</td>\n",
       "      <td>0.751360</td>\n",
       "      <td>0.818086</td>\n",
       "      <td>0.798171</td>\n",
       "      <td>0.748329</td>\n",
       "      <td>0.800451</td>\n",
       "      <td>0.729230</td>\n",
       "      <td>0.842323</td>\n",
       "      <td>0.758460</td>\n",
       "      <td>0.701381</td>\n",
       "      <td>0.805943</td>\n",
       "      <td>0.847231</td>\n",
       "      <td>0.729932</td>\n",
       "      <td>0.704609</td>\n",
       "      <td>0.822478</td>\n",
       "      <td>0.823391</td>\n",
       "      <td>0.731352</td>\n",
       "      <td>0.811611</td>\n",
       "      <td>0.748316</td>\n",
       "      <td>0.848465</td>\n",
       "      <td>0.815230</td>\n",
       "      <td>0.785894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782355</td>\n",
       "      <td>0.679349</td>\n",
       "      <td>0.657832</td>\n",
       "      <td>0.759113</td>\n",
       "      <td>0.594817</td>\n",
       "      <td>0.544871</td>\n",
       "      <td>0.803135</td>\n",
       "      <td>0.830061</td>\n",
       "      <td>0.676949</td>\n",
       "      <td>0.738936</td>\n",
       "      <td>0.687116</td>\n",
       "      <td>0.774896</td>\n",
       "      <td>0.793214</td>\n",
       "      <td>0.631826</td>\n",
       "      <td>0.773584</td>\n",
       "      <td>0.715254</td>\n",
       "      <td>0.726705</td>\n",
       "      <td>0.746340</td>\n",
       "      <td>0.778108</td>\n",
       "      <td>0.776918</td>\n",
       "      <td>0.668761</td>\n",
       "      <td>0.809238</td>\n",
       "      <td>0.668043</td>\n",
       "      <td>0.709980</td>\n",
       "      <td>0.756156</td>\n",
       "      <td>0.793967</td>\n",
       "      <td>0.607917</td>\n",
       "      <td>0.637557</td>\n",
       "      <td>0.791494</td>\n",
       "      <td>0.684709</td>\n",
       "      <td>0.726178</td>\n",
       "      <td>0.844632</td>\n",
       "      <td>0.719388</td>\n",
       "      <td>0.753712</td>\n",
       "      <td>0.787019</td>\n",
       "      <td>0.770069</td>\n",
       "      <td>0.640735</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.788071</td>\n",
       "      <td>0.673620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.689305</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.812324</td>\n",
       "      <td>0.722593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600786</td>\n",
       "      <td>0.775307</td>\n",
       "      <td>0.735864</td>\n",
       "      <td>0.547230</td>\n",
       "      <td>0.601958</td>\n",
       "      <td>0.788993</td>\n",
       "      <td>0.710288</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>0.800858</td>\n",
       "      <td>0.751683</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.860757</td>\n",
       "      <td>0.787650</td>\n",
       "      <td>0.639214</td>\n",
       "      <td>0.731263</td>\n",
       "      <td>0.592789</td>\n",
       "      <td>0.756226</td>\n",
       "      <td>0.759656</td>\n",
       "      <td>0.759283</td>\n",
       "      <td>0.801298</td>\n",
       "      <td>0.635432</td>\n",
       "      <td>0.498798</td>\n",
       "      <td>0.802448</td>\n",
       "      <td>0.561195</td>\n",
       "      <td>0.678202</td>\n",
       "      <td>0.691015</td>\n",
       "      <td>0.735656</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.526903</td>\n",
       "      <td>0.740167</td>\n",
       "      <td>0.817801</td>\n",
       "      <td>0.845239</td>\n",
       "      <td>0.659591</td>\n",
       "      <td>0.690958</td>\n",
       "      <td>0.764449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775696</td>\n",
       "      <td>0.758959</td>\n",
       "      <td>0.750301</td>\n",
       "      <td>0.667466</td>\n",
       "      <td>0.149284</td>\n",
       "      <td>0.629677</td>\n",
       "      <td>0.653324</td>\n",
       "      <td>0.699159</td>\n",
       "      <td>0.317762</td>\n",
       "      <td>0.656449</td>\n",
       "      <td>0.716390</td>\n",
       "      <td>0.690597</td>\n",
       "      <td>0.595044</td>\n",
       "      <td>0.760471</td>\n",
       "      <td>0.558444</td>\n",
       "      <td>0.730936</td>\n",
       "      <td>0.610142</td>\n",
       "      <td>0.603166</td>\n",
       "      <td>0.515101</td>\n",
       "      <td>0.639371</td>\n",
       "      <td>0.810822</td>\n",
       "      <td>0.632039</td>\n",
       "      <td>0.239777</td>\n",
       "      <td>0.806933</td>\n",
       "      <td>0.707522</td>\n",
       "      <td>0.536813</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>0.638223</td>\n",
       "      <td>0.751427</td>\n",
       "      <td>0.777682</td>\n",
       "      <td>0.748921</td>\n",
       "      <td>0.799325</td>\n",
       "      <td>0.544210</td>\n",
       "      <td>0.752086</td>\n",
       "      <td>0.627360</td>\n",
       "      <td>0.775034</td>\n",
       "      <td>0.757307</td>\n",
       "      <td>0.787797</td>\n",
       "      <td>0.740129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2     ...      4797      4798      4799\n",
       "0  1.000000  0.673902  0.751573  ...  0.720340  0.782287  0.690373\n",
       "1  0.673902  1.000000  0.635209  ...  0.593951  0.613347  0.577721\n",
       "2  0.751573  0.635209  1.000000  ...  0.783749  0.799898  0.729796\n",
       "3  0.863714  0.745993  0.776931  ...  0.746616  0.788071  0.673620\n",
       "4  0.689305  0.662533  0.812324  ...  0.757307  0.787797  0.740129\n",
       "\n",
       "[5 rows x 4800 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim = cosine_similarity(elmo_embeddings)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tPuwK8EWnaE2",
    "outputId": "50eb6166-d366-40e8-d170-21ce668b8dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n",
      "Top 5 recommended Movies: ['Shooting Fish' 'Alice Through the Looking Glass'\n",
      " 'My Super Ex-Girlfriend' 'Hocus Pocus' 'Ernest & Celestine']\n",
      "\n",
      "Movie: Interstellar\n",
      "Top 5 recommended Movies: ['The Ice Pirates' 'Transformers: Age of Extinction'\n",
      " '2001: A Space Odyssey' 'Prometheus' 'Sphere']\n",
      "\n",
      "Movie: Deadpool\n",
      "Top 5 recommended Movies: ['The Dark Knight Rises' 'Enough' 'Secret Window'\n",
      " 'The Silence of the Lambs' 'Locker 13']\n",
      "\n",
      "Movie: Jurassic World\n",
      "Top 5 recommended Movies: ['Marmaduke' 'Super Mario Bros.' 'The Shining' 'How to Be Single' 'Cheri']\n",
      "\n",
      "Movie: Pirates of the Caribbean: The Curse of the Black Pearl\n",
      "Top 5 recommended Movies: ['Pirates of the Caribbean: On Stranger Tides' 'Moby Dick' 'Sharknado'\n",
      " 'Dear John' 'Jaws']\n",
      "\n",
      "Movie: Dawn of the Planet of the Apes\n",
      "Top 5 recommended Movies: ['Resident Evil: Extinction' 'Hoot' 'The 13th Warrior' 'The Night Visitor'\n",
      " 'Star Trek: Generations']\n",
      "\n",
      "Movie: The Hunger Games: Mockingjay - Part 1\n",
      "Top 5 recommended Movies: ['Invasion U.S.A.' 'Mirrors' 'Gods of Egypt' 'Furious 7'\n",
      " 'Jekyll and Hyde ... Together Again']\n",
      "\n",
      "Movie: Terminator Genisys\n",
      "Top 5 recommended Movies: ['Idiocracy' 'War' 'Avengers: Age of Ultron' 'Capricorn One'\n",
      " 'Transformers']\n",
      "\n",
      "Movie: Captain America: Civil War\n",
      "Top 5 recommended Movies: ['X-Men: Days of Future Past' 'The Incredible Hulk' 'Gettysburg'\n",
      " 'Star Trek: Insurrection' 'Men of Honor']\n",
      "\n",
      "Movie: The Dark Knight\n",
      "Top 5 recommended Movies: ['The Dark Knight Rises' 'War' 'Beverly Hills Cop II' 'Defendor'\n",
      " 'Tombstone']\n",
      "\n",
      "Movie: The Martian\n",
      "Top 5 recommended Movies: ['Deep Impact' 'Gravity' 'Muppets from Space' 'Silent Running' 'Alien']\n",
      "\n",
      "Movie: Batman v Superman: Dawn of Justice\n",
      "Top 5 recommended Movies: ['Thor' 'The Assassination of Jesse James by the Coward Robert Ford'\n",
      " 'Captain America: The First Avenger' 'Star Trek' 'War']\n",
      "\n",
      "Movie: Pulp Fiction\n",
      "Top 5 recommended Movies: ['Bleeding Hearts' 'Shaun of the Dead' 'The Perks of Being a Wallflower'\n",
      " 'The Poker House' 'Donkey Punch']\n",
      "\n",
      "Movie: The Godfather\n",
      "Top 5 recommended Movies: ['Get Carter' 'In Cold Blood' 'The Black Dahlia' 'GoodFellas'\n",
      " 'Once Upon a Time in America']\n",
      "\n",
      "Movie: The Shawshank Redemption\n",
      "Top 5 recommended Movies: ['Prison' 'Bronson' 'The Whole Nine Yards' 'Brazil' 'Deadpool']\n",
      "\n",
      "Movie: The Lord of the Rings: The Fellowship of the Ring\n",
      "Top 5 recommended Movies: ['New Nightmare' 'Beetlejuice' 'Superman Returns' 'Shrek Forever After'\n",
      " 'Salton Sea']\n",
      "\n",
      "Movie: Harry Potter and the Chamber of Secrets\n",
      "Top 5 recommended Movies: ['Dream with the Fishes' 'Harry Potter and the Half-Blood Prince'\n",
      " 'Alice Through the Looking Glass' \"The Party's Over\"\n",
      " 'The Boys from Brazil']\n",
      "\n",
      "Movie: Star Wars\n",
      "Top 5 recommended Movies: ['You Only Live Twice' 'The Empire Strikes Back' 'DOA: Dead or Alive'\n",
      " 'Dr. No' 'Pirates of the Caribbean: On Stranger Tides']\n",
      "\n",
      "Movie: The Hobbit: The Battle of the Five Armies\n",
      "Top 5 recommended Movies: ['Wrath of the Titans' 'Wild Wild West' 'Braveheart'\n",
      " 'Underworld: Rise of the Lycans' 'Harry Potter and the Goblet of Fire']\n",
      "\n",
      "Movie: Iron Man\n",
      "Top 5 recommended Movies: ['Iron Man 3' 'Love in the Time of Monsters' 'Yoga Hosers' 'Tycoon'\n",
      " 'The Matrix']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text Content Recommenders.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
